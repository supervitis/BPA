{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 3 (Exercise) - Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the exercise of the third session of the lecture **1743 - Data Mining and Decision Support Systems** held by Prof. Nils Löhndorf at the Vienna University of Economics and Business during the winter term 2016/2017. It was conducted by group WU6 consisting of Boris Haviar, David Riobo Barba and Manuel Raffel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "*1. Use the `SGDClassifier` provided by scikit-learn. Set `loss='log'`, `learning_rate='constant'`, `alpha=0.0`, `random_state=191`. Set `n_iter=10`, so that the SGDClassifier will sweep the sample 10 times. The stepsize is defined by the parameter `eta0`. Use 5-fold cross validation to search for a good eta0.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import *\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.cross_validation import KFold\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The used data is the same as in lesson 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>Spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.76</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5.11</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.01</td>\n",
       "      <td>9.82</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.54</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.54</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9  ...    48   49   50   51  \\\n",
       "0 0.00 0.64 0.64 0.00 0.32 0.00 0.00 0.00 0.00 0.00  ...  0.00 0.00 0.00 0.78   \n",
       "1 0.21 0.28 0.50 0.00 0.14 0.28 0.21 0.07 0.00 0.94  ...  0.00 0.13 0.00 0.37   \n",
       "2 0.06 0.00 0.71 0.00 1.23 0.19 0.19 0.12 0.64 0.25  ...  0.01 0.14 0.00 0.28   \n",
       "3 0.00 0.00 0.00 0.00 0.63 0.00 0.31 0.63 0.31 0.63  ...  0.00 0.14 0.00 0.14   \n",
       "4 0.00 0.00 0.00 0.00 0.63 0.00 0.31 0.63 0.31 0.63  ...  0.00 0.14 0.00 0.14   \n",
       "\n",
       "    52   53   54   55    56  Spam  \n",
       "0 0.00 0.00 3.76   61   278     1  \n",
       "1 0.18 0.05 5.11  101  1028     1  \n",
       "2 0.18 0.01 9.82  485  2259     1  \n",
       "3 0.00 0.00 3.54   40   191     1  \n",
       "4 0.00 0.00 3.54   40   191     1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('http://statweb.stanford.edu/~tibs/ElemStatLearn/datasets/spam.data', \n",
    "                 engine='python', sep='\\\\s', header=None)\n",
    "feat_index = range(57)\n",
    "df.columns = feat_index + ['Spam']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the data is ordered by the binary response \"Spam\", it needs to be shuffled so that the folds generated by the KFold-Algorithm have distinct values for this variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.reindex(np.random.permutation(df.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "To compute the best possible score, the eta0 is \"brute-forced\" by increasing it in steps of 0.0001 from 0 to 1. For every eta0, a SGDClassifier with the parameters given in the task is created. By using 5-fold cross validation, the accuracy is calculated and, if it is better than the previous best, stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10000 of 10000 (current eta: 1.0 | current score: 0.653447285119 | best eta: 0.3937 | best score: 0.697130195599)\n",
      "accuracy: 69.7 percent with an eta0 of 0.3937\n"
     ]
    }
   ],
   "source": [
    "X = df[feat_index].values\n",
    "y = df.Spam.values\n",
    "n = len(df)\n",
    "best_eta = 0.0001\n",
    "best_score = 0\n",
    "for eta in xrange(1, 10001):\n",
    "    avg_score = 0\n",
    "    sgd = SGDClassifier(loss='log', alpha=0.0, n_iter=10, random_state=191, learning_rate='constant', eta0=(eta/10000.0))\n",
    "    for test, train in KFold(n, n_folds=5):\n",
    "        X_test, X_train = X[test], X[train]\n",
    "        y_test, y_train = y[test], y[train]\n",
    "        sgd.fit(X_train, y_train)\n",
    "        avg_score += sgd.score(X_test, y_test)/5\n",
    "    if avg_score > best_score:\n",
    "        best_score = avg_score\n",
    "        best_eta = (eta/10000.0)\n",
    "    sys.stdout.write(\"\\rStep \" + str(eta) + \" of 10000 (current eta: \" + str(eta/10000.0) + \n",
    "                     \" | current score: \" + str(avg_score) + \" | best eta: \" + str(best_eta) + \n",
    "                     \" | best score: \" + str(best_score) + \")\")\n",
    "print(\"\\naccuracy: %.1f percent\"%(100*best_score) + \" with an eta0 of \" + str(best_eta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "*2. Implement a variant of logistic regression using stochastic gradient ascent with AdaGrad stepsizes. Make sure that the sample size is 10 times the training set size, so that your classifier sees as many data points as the SGDClassifier.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to already prepare for task 3, the variant was already implemented as a class, `SGAdaGradClassifier`. It's `fit(X,y,n_iter)`-method per default adjusts its sample size by multiplying the sample length with 10 to account for comparability to the `n_iter=10` used by the SGDClassifier above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class SGAdaGradClassifier:\n",
    "    def fit(self, X, y, n_iter='default'):\n",
    "        n = len(X)\n",
    "        b = np.zeros(len(X[0]))\n",
    "        G = 1\n",
    "        \n",
    "        if n_iter == 'default':\n",
    "            size = 10*len(X) # adjust sample size for comparability per default\n",
    "        else: \n",
    "            size = n_iter\n",
    "    \n",
    "        # stochastic gradient ascent with AdaGrad stepsize\n",
    "        for j in range(size):\n",
    "            i = random.randint(0,n-1)\n",
    "            grad = (y[i]-(1 + np.exp(min(50,-b.dot(X[i]))))**-1)*X[i]\n",
    "            G += grad**2\n",
    "            b += grad/G**0.5\n",
    "            \n",
    "        self.b = b\n",
    "        \n",
    "    def score(self, X, y):\n",
    "        est_correct = 0\n",
    "        \n",
    "        for i in range(len(X)):\n",
    "            isSpam = y[i]\n",
    "            isSpamEstimation = (1 + math.exp(min(50,-self.b.dot(X[i]))))**-1\n",
    "            \n",
    "            # isSpamEstimation mostly is either close to 0 or close to 1, \n",
    "            # for the values in between we only identify it as spam if the estimation is really close to 1\n",
    "            if isSpamEstimation <= 0.99:\n",
    "                isSpamEstimation = 0\n",
    "            else:\n",
    "                isSpamEstimation = 1\n",
    "                \n",
    "            if isSpamEstimation == isSpam:\n",
    "                est_correct += 1\n",
    "                \n",
    "        return float(est_correct) / len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the implemented SGAdaGradClassifier, the same 5-fold cross validation as above is used. It appears its accuracy is higher than the one of SGDClassifier, normally yielding values bigger than 80%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 88.1 percent\n"
     ]
    }
   ],
   "source": [
    "avg_score = 0\n",
    "sga = SGAdaGradClassifier()\n",
    "for test, train in KFold(n, n_folds=5):\n",
    "    X_test, X_train = X[test], X[train]\n",
    "    y_test, y_train = y[test], y[train]\n",
    "    sga.fit(X_train, y_train)\n",
    "    avg_score += sga.score(X_test, y_test)/5\n",
    "print(\"accuracy: %.1f percent\"%(100*avg_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "*3. Compare your own classifier against the SGDClassifier and LogisticRegression using the function `accuracy_dist()`. Note that, for this you should implement the classifier in its own class which must implement the functions `fit(X,y)` and `score(X,y)`. The trick is to use a class variable for the parameters, e.g., `self.beta`, which can be accessed in both functions. If creating a class seems to difficult a function that does both, fitting and scoring, will also do the trick.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `accuracy_dist()` is taken straight from lesson 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy_dist(clfs, X, y, n=10):\n",
    "    accuracy = np.zeros((n,len(clfs)))\n",
    "    columns = [clf.__class__.__name__ for clf in clfs]\n",
    "    for i in range(n):\n",
    "        X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, random_state=31*i)\n",
    "        for j in range(len(clfs)):\n",
    "            clf = clfs[j]\n",
    "            clf.fit(X_train,y_train)\n",
    "            accuracy[i][j] = clf.score(X_test,y_test)\n",
    "    return pd.DataFrame(accuracy, columns=columns, index=range(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To keep up the comparability to the SGAdaGradClassifier, the SGDClassifiert is again initialized with `n_iter=10`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEACAYAAAC+gnFaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\naecsERhjTDtnicAYY9q5/wfRuEKXYQ0WKgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4a4561bed0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracy_df = accuracy_dist([SGAdaGradClassifier(),\n",
    "                             SGDClassifier(loss='log', alpha=0.0, n_iter=10, random_state=191, \n",
    "                                           learning_rate='constant', eta0=best_eta),\n",
    "                             LogisticRegression()], X, y)\n",
    "accuracy_df.plot(kind='kde', ylim=[0,60])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As already concluded after task 2, the SGAdaGradClassifier in general performs better than the SGDClassifier, although worse than logistic regression."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
